# Interview Confidence Analyzer

> A multimodal AI framework that analyzes candidate confidence in interviews using **facial cues** and **spoken responses** in real-time.

---

## ðŸ“Œ Overview

The **Interview Confidence Analyzer** is a framework designed to simulate mock interview sessions and evaluate a candidate's confidence level using:

- ðŸŽ¥ **Visual cues** (via webcam)
- ðŸŽ¤ **Verbal cues** (via speech transcription enhanced with agentic based dynamic question generation on selected topic and ansswer verification )

This project integrates **Computer Vision (MediaPipe + OpenCV)** and **Natural Language Processing (Whisper)** alongside an pipeline of LLM based retrival and rendering to provide real-time feedback on how confident and focused the user appears during a live quiz/interview.

---

## ðŸ” Use Cases

- ðŸ§‘â€ðŸŽ“ **Students** practicing for job interviews.
- ðŸ§‘â€ðŸ’¼ **Professionals** preparing for client meetings or public speaking.
- ðŸ§‘â€ðŸ« **Coaching institutes** running mock interview tests.
- ðŸ§‘â€ðŸ’¼ **HR tech prototypes** to explore emotion-aware recruitment.

---

## ðŸ§¬ System Pipeline

```mermaid
graph LR
A[Live Video Feed] --> B[MediaPipe Landmark Detection]
B --> C[Facial Cues: EAR, MAR, Gaze, Eyebrow Raise]
C --> D[Visual Confidence Score]

E[Microphone Input] --> F[Whisper Speech-to-Text]
F --> G[Verbal Analysis (Transcript Confidence) using LLM pipeline and microservice architectured based communication]
G --> H[Verbal Confidence Score]

D & H --> I[Fusion Layer]
I --> J[Final Confidence Score]
J --> K[Display on UI / Save to File]
